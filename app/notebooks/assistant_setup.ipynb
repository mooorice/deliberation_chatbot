{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import backoff\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from fastapi import HTTPException\n",
    "\n",
    "import json\n",
    "\n",
    "def show_json(obj):\n",
    "    display(json.loads(obj.model_dump_json()))\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = \"What is the position of the CDU on environmental policy?\"\n",
    "thread = \"thread_Co1ZF7iG67Ixtoh7siBZ9w17\"\n",
    "assistant = \"asst_hAFjnviViYmwcv6CiO07DRgh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[Message](data=[Message(id='msg_zpEQ914ioFWBPfZFiCFHKPhd', assistant_id='asst_hAFjnviViYmwcv6CiO07DRgh', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[FileCitationAnnotation(end_index=1437, file_citation=FileCitation(file_id='file-pXAKBOR2c84Z9ezkSYXj2ws9', quote=None), start_index=1425, text='【6:0†Quelle】', type='file_citation')], value='Vielen Dank für Ihre Frage zur Umweltpolitik der CDU. Die CDU setzt sich für eine \"vertretbare und durchdachte Umweltpolitik\" ein, die globale Zusammenarbeit betont und versucht, eine Balance zwischen ökologischer Verantwortung und wirtschaftlicher Entwicklung zu finden. Hier sind einige der wichtigsten Punkte ihrer Umweltpolitik:\\n\\n1. **Nachhaltige Energieversorgung:** Förderung erneuerbarer Energien wie Windkraft und Solarenergie, um die Abhängigkeit von fossilen Brennstoffen zu reduzieren und eine umweltfreundliche Energieversorgung sicherzustellen.\\n\\n2. **Energieeffizienz und Innovation:** Verbesserung der Energieeffizienz in verschiedenen Sektoren wie Industrie, Verkehr und privaten Haushalten durch innovative Lösungen und Förderung von Forschung und Entwicklung.\\n\\n3. **Soziale und wirtschaftliche Verträglichkeit:** Sicherstellung, dass Umweltschutzpolitik nicht zu unverhältnismäßigen Teuerungen für private Haushalte und energieintensive Wirtschaftssektoren führt.\\n\\n4. **Globale Kooperation und Verantwortung:** Aktive Rolle Europas in globalen Umweltabkommen und Förderung von Umweltschutzmaßnahmen weltweit.\\n\\n5. **Vorbeugung von Abhängigkeiten:** Diversifizierung der Energiequellen und Stärkung der Energieunabhängigkeit Europas.\\n\\n6. **Atomkraft:** Befürwortung einer sorgfältigen und wissenschaftlich fundierten Prüfung der Möglichkeit, Atomenergie unter strengsten Sicherheitsvorkehrungen wiederzubeleben【6:0†Quelle】.\\n\\nWelche Aspekte dieser Position sprechen Sie besonders an, oder gibt es Punkte, bei denen Sie eher skeptisch sind?'), type='text')], created_at=1716806903, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_DxEnLrMQVRY1tmFwQONoQLlO', status=None, thread_id='thread_Co1ZF7iG67Ixtoh7siBZ9w17')], object='list', first_id='msg_zpEQ914ioFWBPfZFiCFHKPhd', last_id='msg_zpEQ914ioFWBPfZFiCFHKPhd', has_more=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a message to append to our thread\n",
    "bot_message = client.beta.threads.messages.create(\n",
    "    thread_id=thread, role='user', content=user_message)\n",
    "# Execute our run\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread,\n",
    "    assistant_id=assistant,\n",
    ")\n",
    "response = client.beta.threads.messages.list(thread_id=thread, run_id=run.id)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file-pXAKBOR2c84Z9ezkSYXj2ws9'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.data[0].content[0].text.annotations[0].file_citation.file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List\n",
    "\n",
    "def extract_citations(response) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extracts the citations from the response content.\n",
    "    \n",
    "    Parameters:\n",
    "    response (SyncCursorPage[Message]): The response object containing messages.\n",
    "    \n",
    "    Returns:\n",
    "    List[str]: A list of citations found in the message content.\n",
    "    \"\"\"\n",
    "    citations = []\n",
    "    for message in response.data:\n",
    "        for content_block in message.content:\n",
    "            if isinstance(content_block, TextContentBlock):\n",
    "                text_content = content_block.text.value\n",
    "                citations.extend(re.findall(r'【\\d+:\\d+†Quelle】', text_content))\n",
    "    return citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TextContentBlock' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m citations \u001b[38;5;241m=\u001b[39m \u001b[43mextract_citations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m citations\n",
      "Cell \u001b[0;32mIn[6], line 17\u001b[0m, in \u001b[0;36mextract_citations\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mdata:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m content_block \u001b[38;5;129;01min\u001b[39;00m message\u001b[38;5;241m.\u001b[39mcontent:\n\u001b[0;32m---> 17\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_block, \u001b[43mTextContentBlock\u001b[49m):\n\u001b[1;32m     18\u001b[0m             text_content \u001b[38;5;241m=\u001b[39m content_block\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m     19\u001b[0m             citations\u001b[38;5;241m.\u001b[39mextend(re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m【\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+†Quelle】\u001b[39m\u001b[38;5;124m'\u001b[39m, text_content))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TextContentBlock' is not defined"
     ]
    }
   ],
   "source": [
    "citations = extract_citations(response)\n",
    "citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[VectorStoreFile](data=[VectorStoreFile(id='file-JJwGAvONFPfg5uta5MYKdgiw', created_at=1716808241, last_error=None, object='vector_store.file', status='completed', usage_bytes=None, vector_store_id='vs_irHI3SzaGFUo8Hu20DFqThpc'), VectorStoreFile(id='file-7BS9opE9sX7JzjfrFR9B90bc', created_at=1716808241, last_error=None, object='vector_store.file', status='completed', usage_bytes=None, vector_store_id='vs_irHI3SzaGFUo8Hu20DFqThpc'), VectorStoreFile(id='file-bssLEKFoeKt8eujiImgfzCaj', created_at=1716808241, last_error=None, object='vector_store.file', status='completed', usage_bytes=None, vector_store_id='vs_irHI3SzaGFUo8Hu20DFqThpc'), VectorStoreFile(id='file-LNGmxxL5LGiKfIApiKVYSJJ5', created_at=1716808241, last_error=None, object='vector_store.file', status='completed', usage_bytes=None, vector_store_id='vs_irHI3SzaGFUo8Hu20DFqThpc'), VectorStoreFile(id='file-apG4Nas7BVCgFnDBdnXme3In', created_at=1716808241, last_error=None, object='vector_store.file', status='completed', usage_bytes=None, vector_store_id='vs_irHI3SzaGFUo8Hu20DFqThpc'), VectorStoreFile(id='file-YfCoMeltuNJM7txtVUTOh4xo', created_at=1716808241, last_error=None, object='vector_store.file', status='completed', usage_bytes=None, vector_store_id='vs_irHI3SzaGFUo8Hu20DFqThpc'), VectorStoreFile(id='file-wphnE0guGoLrtfGsO185A2Uv', created_at=1716808241, last_error=None, object='vector_store.file', status='completed', usage_bytes=None, vector_store_id='vs_irHI3SzaGFUo8Hu20DFqThpc'), VectorStoreFile(id='file-IcjvRVrWoejodwfe551RDKgm', created_at=1716808241, last_error=None, object='vector_store.file', status='completed', usage_bytes=None, vector_store_id='vs_irHI3SzaGFUo8Hu20DFqThpc'), VectorStoreFile(id='file-vApujohyqiKuAupTANd8SQgv', created_at=1716808241, last_error=None, object='vector_store.file', status='completed', usage_bytes=None, vector_store_id='vs_irHI3SzaGFUo8Hu20DFqThpc'), VectorStoreFile(id='file-cgz6vUpRmS5j0tzgj51bS43y', created_at=1716808241, last_error=None, object='vector_store.file', status='completed', usage_bytes=None, vector_store_id='vs_irHI3SzaGFUo8Hu20DFqThpc'), VectorStoreFile(id='file-64ajopPH5DLUgsP1PqKUuj4F', created_at=1716808241, last_error=None, object='vector_store.file', status='completed', usage_bytes=None, vector_store_id='vs_irHI3SzaGFUo8Hu20DFqThpc'), VectorStoreFile(id='file-GzmGIlkra1P8Y742Nx57CNum', created_at=1716808241, last_error=None, object='vector_store.file', status='completed', usage_bytes=None, vector_store_id='vs_irHI3SzaGFUo8Hu20DFqThpc'), VectorStoreFile(id='file-zeLIt8wmNWwE9sc3rg5fZd2I', created_at=1716808241, last_error=None, object='vector_store.file', status='completed', usage_bytes=None, vector_store_id='vs_irHI3SzaGFUo8Hu20DFqThpc'), VectorStoreFile(id='file-9ntEvQH6VUY9tYQgM7riX8vE', created_at=1716808241, last_error=None, object='vector_store.file', status='completed', usage_bytes=None, vector_store_id='vs_irHI3SzaGFUo8Hu20DFqThpc'), VectorStoreFile(id='file-PtwSCrLl0VCxE7On8vVCrJfb', created_at=1716808241, last_error=None, object='vector_store.file', status='completed', usage_bytes=None, vector_store_id='vs_irHI3SzaGFUo8Hu20DFqThpc'), VectorStoreFile(id='file-jbn3fEi1aKj3z6fwEl9NcKqr', created_at=1716808241, last_error=None, object='vector_store.file', status='completed', usage_bytes=None, vector_store_id='vs_irHI3SzaGFUo8Hu20DFqThpc'), VectorStoreFile(id='file-Sb0VozJQaMRIcz9fFYbeZ7Se', created_at=1716808241, last_error=None, object='vector_store.file', status='completed', usage_bytes=None, vector_store_id='vs_irHI3SzaGFUo8Hu20DFqThpc'), VectorStoreFile(id='file-ybsWyoOeDTwKNJWh0zYMVqRp', created_at=1716808241, last_error=None, object='vector_store.file', status='completed', usage_bytes=None, vector_store_id='vs_irHI3SzaGFUo8Hu20DFqThpc'), VectorStoreFile(id='file-6lsvKzjf9tbtN9jEohDCaKFG', created_at=1716808241, last_error=None, object='vector_store.file', status='completed', usage_bytes=None, vector_store_id='vs_irHI3SzaGFUo8Hu20DFqThpc'), VectorStoreFile(id='file-CvfaTzpYsKzrKaDnFru7tO1A', created_at=1716808241, last_error=None, object='vector_store.file', status='completed', usage_bytes=None, vector_store_id='vs_irHI3SzaGFUo8Hu20DFqThpc')], object='list', first_id='file-JJwGAvONFPfg5uta5MYKdgiw', last_id='file-CvfaTzpYsKzrKaDnFru7tO1A', has_more=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.beta.vector_stores.file_batches.list_files(vector_store_id='vs_irHI3SzaGFUo8Hu20DFqThpc', batch_id='vsfb_fd215f6f863f4a86965be6e206d35454')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.beta.vector_stores.files.upload_and_poll(vector_store_id='vs_irHI3SzaGFUo8Hu20DFqThpc', batch_id='vsfb_fd215f6f863f4a86965be6e206d35454', file='vsf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/ABG.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/ABG.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.8/envs/delibenv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/ABG.pdf'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[Assistant](data=[Assistant(id='asst_TleKd7WyfFmMKCCggzlbwRLd', created_at=1716803821, description=None, instructions=\"You're an AI designed to engage in casual conversation with your discussion partner. Your goal is to have a light-hearted \\n                            and fun conversation with your partner. Make sure to be friendly and introduce yourself. Ask about their day and interests. \\n                            Share some fun facts or jokes and ask about their opinion on various topics. Make sure to discuss in german and make sure \\n                            not to overwhelm your discussion partner with too many questions or too much information. Limit yourself to 1 question per message.\\n                            \", metadata={}, model='gpt-4o', name='Casual Assistant', object='assistant', tools=[FileSearchTool(type='file_search')], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=ToolResourcesFileSearch(vector_store_ids=[])), top_p=1.0)], object='list', first_id='asst_TleKd7WyfFmMKCCggzlbwRLd', last_id='asst_TleKd7WyfFmMKCCggzlbwRLd', has_more=False)\n"
     ]
    }
   ],
   "source": [
    "response = client.beta.assistants.list()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AssistantDeleted(id='asst_TleKd7WyfFmMKCCggzlbwRLd', deleted=True, object='assistant.deleted')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.beta.assistants.delete(response.data[0].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VectorStore(id='vs_irHI3SzaGFUo8Hu20DFqThpc', created_at=1716808221, file_counts=FileCounts(cancelled=0, completed=35, failed=0, in_progress=0, total=35), last_active_at=1716808255, metadata={}, name='Party Programs', object='vector_store', status='completed', usage_bytes=6851336, expires_after=None, expires_at=None)]\n"
     ]
    }
   ],
   "source": [
    "response = client.beta.vector_stores.list()\n",
    "print(response.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreDeleted(id='vs_1oaow1PUlLGDgR9XG4uFL5Ul', deleted=True, object='vector_store.deleted')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.beta.vector_stores.delete(response.data[0].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asst_TwWxtHZvL7Yyt6zEWV1wZ1k5'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.data[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create a question conversation\n",
    "def get_question_conversation():\n",
    "    \"\"\"\n",
    "    Returns a conversation starter for a question discussion.\n",
    "    \"\"\"\n",
    "        \n",
    "    system_prompt = f\"\"\"\n",
    "    You're an AI designed to check the quality of the answers provided by another assistant.\n",
    "    Your only job is to check that there is only one question in every message. \n",
    "    If there is more than one question, you should rewrite the message to contain only one question.\n",
    "    Pick the most critical question in the message and keep it.\n",
    "    Do not change the rest of the message unless you have to in order to adjust for the context of the question.\n",
    "    \"\"\"\n",
    "\n",
    "    conversation_start = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": system_prompt,\n",
    "        }]\n",
    "    return conversation_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function to create a new question conversation thread\n",
    "@backoff.on_exception(backoff.expo, Exception, max_tries=5)\n",
    "async def create_question_thread(assistant):\n",
    "    \"\"\"\n",
    "    Takes assistant as input.\n",
    "    \n",
    "    Creates a new question conversation thread.\n",
    "    \n",
    "    Returns the created thread.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Create a new conversation thread\n",
    "        thread = client.beta.threads.create(\n",
    "                            messages=get_question_conversation(),\n",
    "                            )\n",
    "        \n",
    "        # Create and poll the run\n",
    "        run = client.beta.threads.runs.create_and_poll(\n",
    "            thread_id=thread.id, assistant_id=assistant\n",
    "        )\n",
    "        client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id)\n",
    "        return thread\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Failed to create question conversation: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = create_question_thread(\"asst_pluDj7W9S65tz0yHR5w0t7nm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create(\n",
    "                messages=get_question_conversation(),\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create_and_poll(\n",
    "            thread_id=thread.id, assistant_id=\"asst_pluDj7W9S65tz0yHR5w0t7nm\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[Message](data=[Message(id='msg_hHncd621QmjDxbsQEiRAvQUw', assistant_id='asst_pluDj7W9S65tz0yHR5w0t7nm', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Understood, please provide the messages you need reviewed.'), type='text')], created_at=1716802423, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_p4FWvYabjqzbkLrtTOqi8U6e', status=None, thread_id='thread_pnWAMRydead3xtTeIpvHTYTs')], object='list', first_id='msg_hHncd621QmjDxbsQEiRAvQUw', last_id='msg_hHncd621QmjDxbsQEiRAvQUw', has_more=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = client.beta.threads.runs.create_and_poll(\n",
    "            thread_id=thread.id, assistant_id=assistant\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object ensure_vector_store at 0x70db327903c0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensure_vector_store(response.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As in openai_assistant.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create an assistant, if not found\n",
    "@backoff.on_exception(backoff.expo, Exception, max_tries=5)\n",
    "async def create_assistant():\n",
    "    try:\n",
    "        # Making a call to create an assistant\n",
    "        assistant = client.beta.assistants.create(\n",
    "            name=\"Party Analyst Assistant\",\n",
    "            instructions=\"You are an expert political analyst. Use your knowledge base to answer questions about party positions.\",\n",
    "            model=\"gpt-4-turbo\",\n",
    "            tools=[{\"type\": \"file_search\"}],\n",
    "        )\n",
    "        print(f\"Assistant created with ID: {assistant.id}\")\n",
    "        return assistant\n",
    "    except Exception as e:\n",
    "        print(\"Failed to create assistant:\", e)\n",
    "        raise HTTPException(status_code=500, detail=f\"Failed to create assistant: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get an assistant, returns the ID of the Political Analyst Assistant if found and creates a new one if not found\n",
    "@backoff.on_exception(backoff.expo, Exception, max_tries=5)\n",
    "async def get_assistant():\n",
    "    try:\n",
    "        # Making a call to list assistantsassistant\n",
    "        response = client.beta.assistants.list()  # Fetching all the assistants\n",
    "        if response and response.data:\n",
    "            for assistant in response.data:\n",
    "                if assistant.name == \"Party Analyst Assistant\":\n",
    "                    print(\"Party Analyst Assistant found.\")\n",
    "                    return assistant\n",
    "            # If no assistant found in the loop, create a new one\n",
    "            print(\"No Party Analyst Assistant found within, creating a new one...\")\n",
    "            assistant = await create_assistant()\n",
    "            return assistant\n",
    "        else:\n",
    "            print(\"No assistants or data available or failed to fetch data, attempting to create a new assistant.\")\n",
    "            assistant = await create_assistant()\n",
    "            return assistant\n",
    "    except Exception as e:\n",
    "        print(\"Failed to fetch assistants:\", e)\n",
    "        raise HTTPException(status_code=500, detail=f\"Failed to fetch assistants: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to ensure the vector store is attached to the assistant\n",
    "@backoff.on_exception(backoff.expo, Exception, max_tries=5)\n",
    "async def ensure_vector_store(assistant):\n",
    "    try:\n",
    "        # Check if the current assistant has the correct vector store attached\n",
    "        vector_store_ids = assistant.tool_resources.file_search.vector_store_ids if assistant.tool_resources and assistant.tool_resources.file_search else []\n",
    "\n",
    "        if vector_store_ids:\n",
    "            # Fetch the vector store details\n",
    "            vector_store = client.beta.vector_stores.retrieve(vector_store_id=vector_store_ids[0])\n",
    "            if vector_store and vector_store.name == \"Party Positions\":\n",
    "                print(\"Correct vector store already attached.\")\n",
    "                return vector_store\n",
    "            else:\n",
    "                print(\"Incorrect vector store attached, looking for correct vector store.\")\n",
    "        else:\n",
    "            print(\"No vector store attached, looking for correct vector store.\")\n",
    "\n",
    "        # If the correct vector store is not attached, check if such a store exists\n",
    "        all_stores = client.beta.vector_stores.list()\n",
    "        party_positions_store = next((store for store in all_stores.data if store.name == \"Party Positions\"), None)\n",
    "\n",
    "        if party_positions_store:\n",
    "            vector_store_id = party_positions_store.id\n",
    "            print(f\"Vector store 'Party Positions' found with ID: {vector_store_id}\")\n",
    "        else:\n",
    "            # Create a new vector store if not found\n",
    "            print(\"Creating new vector store 'Party Positions'\")\n",
    "            vector_store = client.beta.vector_stores.create(name=\"Party Positions\")\n",
    "            vector_store_id = vector_store.id\n",
    "\n",
    "            # Upload files to the new vector store\n",
    "            file_paths = [\"../data/party_positions.pdf\"] # File path to the PDF file\n",
    "            file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "            file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "                vector_store_id=vector_store_id, files=file_streams\n",
    "            )\n",
    "            print(f\"Files uploaded to vector store: {file_batch.status}\")\n",
    "\n",
    "        # Attach the vector store to the assistant\n",
    "        updated_assistant = client.beta.assistants.update(\n",
    "            assistant_id=assistant.id,\n",
    "            tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store_id]}}\n",
    "        )\n",
    "        print(f\"Vector store '{vector_store_id}' attached to assistant.\")\n",
    "        return vector_store\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Failed to ensure vector store:\", e)\n",
    "        raise HTTPException(status_code=500, detail=f\"Failed to ensure vector store: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function to create a new conversation thread\n",
    "@backoff.on_exception(backoff.expo, Exception, max_tries=5)\n",
    "async def create_conversation(assistant, vector_store):\n",
    "    try:\n",
    "        # Create a new conversation thread\n",
    "        thread = client.beta.threads.create(\n",
    "                            messages=conversation_start,\n",
    "                            tool_resources={\n",
    "                                \"file_search\": {\n",
    "                                    \"vector_store_ids\": [vector_store.id]\n",
    "                                }\n",
    "                            }\n",
    "                        )\n",
    "        print(f\"Conversation thread created with ID: {thread.id}\")\n",
    "        \n",
    "        # Create and poll the run\n",
    "        run = client.beta.threads.runs.create_and_poll(\n",
    "            thread_id=thread.id, assistant_id=assistant.id\n",
    "        )\n",
    "        print(f\"Run created with ID: {run.id}\")\n",
    "        return thread, run\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Failed to create conversation: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to run the setup\n",
    "@backoff.on_exception(backoff.expo, Exception, max_tries=5)\n",
    "async def assistant_setup():\n",
    "    try:\n",
    "        # Step 1: Get or create the assistant\n",
    "        assistant = await get_assistant()\n",
    "\n",
    "        # Step 2: Ensure the assistant has the correct vector store attached\n",
    "        vector_store = await ensure_vector_store(assistant)\n",
    "        \n",
    "        # Step 3: Create a new conversation thread\n",
    "        thread, run = await create_conversation(assistant, vector_store)\n",
    "        \n",
    "        # Step 4: Get the response from the assistant\n",
    "        conversation = {}\n",
    "        response = client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id)\n",
    "        conversation['assistant'] = [response.data[0].content[0].text.value]\n",
    "        conversation['user'] = []\n",
    "        return assistant, vector_store, thread, run, conversation\n",
    "\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You're an AI political guide designed to engage in Socratic dialogue. Your goal is to help your discussion \n",
    "partner in self-deliberation about their political opinions. Make sure not to nudge your partner into any \n",
    "political direction but instead be curious and help them find out more deeply what beliefs and opinions they \n",
    "hold and why that is.\n",
    "\n",
    "Begin the conversation with a greeting and and invitation to the discussion partner to share the political \n",
    "topics that concern them the most. Prompt them to select one topic to delve into first.\n",
    "\n",
    "Opening Inquiry: Start with an open-ended question to explore their initial thoughts about the chosen topic:\n",
    "'What concerns you most about this topic and why do you think it's important?'\n",
    "\n",
    "Deepening Understanding: Once they respond, guide them deeper into their reasoning. Ask questions that probe\n",
    "the logic and evidence behind their views: 'What makes you believe that this is the best approach? Can you \n",
    "share examples or evidence that support your opinion?'\n",
    "\n",
    "Introducing Challenges: After understanding their argument, introduce a counterpoint or challenge to their \n",
    "view to test the robustness of their reasoning: 'Have you considered [a specific contradiction or different \n",
    "perspective]? How does this aspect affect your viewpoint?'\n",
    "\n",
    "Reformulating Opinion: Encourage them to reflect on the counterpoint and adjust their opinion if necessary: \n",
    "'Given this new information, how might you refine your perspective on [Topic]?'\n",
    "\n",
    "Continuation or Change: Before moving on, ask if they want to delve deeper into the same topic or switch to \n",
    "another concern: 'Would you like to explore this topic further, or shall we discuss another one of your \n",
    "concerns?'\n",
    "\n",
    "Repeat these steps for each topic they are concerned about. Once all topics are discussed, conclude by \n",
    "asking if there are any additional topics they wish to explore or if they have any final thoughts to share.\n",
    "\n",
    "This approach ensures a thorough, reflective conversation, helping your discussion partner critically \n",
    "examine and potentially broaden and deepen their political perspectives.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "conversation_start = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": system_prompt,\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Party Analyst Assistant found.\n",
      "Correct vector store already attached.\n",
      "Conversation thread created with ID: thread_lNO64NtObYu0vSRsY3ZkwN7H\n",
      "Run created with ID: run_PguHmmBOLDeoZNMtWzV41Sy9\n"
     ]
    }
   ],
   "source": [
    "assistant, vector_store, thread, run, conversation = await assistant_setup() \n",
    "conversation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Chatbot Completion Function for assistants API\n",
    "@backoff.on_exception(backoff.expo, Exception, max_tries=5)\n",
    "async def chatbot_completion(\n",
    "    message,\n",
    "    assistant,\n",
    "    thread,\n",
    "    run,\n",
    "    conversation\n",
    "    ):\n",
    "    try:\n",
    "        conversation[\"user\"].append(message)\n",
    "        # Create a message to append to our thread\n",
    "        message = client.beta.threads.messages.create(\n",
    "            thread_id=thread.id, role='user', content=message)\n",
    "        \n",
    "        # Execute our run\n",
    "        run = client.beta.threads.runs.create_and_poll(\n",
    "            thread_id=thread.id,\n",
    "            assistant_id=assistant.id,\n",
    "        )\n",
    "        response = client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id)\n",
    "        conversation['assistant'].append(response.data[0].content[0].text.value)\n",
    "\n",
    "        return conversation\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'assistant': [\"Hello! I'm here to help you explore and reflect on your political opinions through a Socratic dialogue. To begin, could you share some political topics that currently concern you the most? Please feel free to list a few, and then we can select one to delve into deeply first.\",\n",
       "  \"Thank you for sharing your concern about job security and the impact of immigration on employment. Let's delve into this topic a bit deeper.\\n\\nWhat concerns you most about this topic and why do you think it's important?\",\n",
       "  \"It sounds like you're deeply concerned about the welfare and financial stability of long-standing communities and their ability to find sustainable employment. \\n\\nWhat makes you believe that the presence of immigrants is a primary factor affecting job availability for locals? Can you share any specific examples or evidence that support your opinion?\"],\n",
       " 'user': [\"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  'I believe a lot of people that belong here and are working hard are not getting the jobs they need to sustain their families.']}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = await chatbot_completion(\n",
    "    message=\"I believe a lot of people that belong here and are working hard are not getting the jobs they need to sustain their families.\",\n",
    "    assistant=assistant,\n",
    "    thread=thread,\n",
    "    run=run,\n",
    "    conversation=conversation\n",
    "    )\n",
    "conversation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delibenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
