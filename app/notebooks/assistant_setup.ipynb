{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import backoff\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from fastapi import HTTPException\n",
    "\n",
    "import json\n",
    "\n",
    "def show_json(obj):\n",
    "    display(json.loads(obj.model_dump_json()))\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[Assistant](data=[], object='list', first_id=None, last_id=None, has_more=False)\n"
     ]
    }
   ],
   "source": [
    "response = client.beta.assistants.list()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39massistants\u001b[38;5;241m.\u001b[39mdelete(\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mid)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "client.beta.assistants.delete(response.data[0].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "response = client.beta.vector_stores.list()\n",
    "print(response.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mvector_stores\u001b[38;5;241m.\u001b[39mdelete(\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mid)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "client.beta.vector_stores.delete(response.data[0].id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As in openai_assistant.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create an assistant, if not found\n",
    "@backoff.on_exception(backoff.expo, Exception, max_tries=5)\n",
    "async def create_assistant():\n",
    "    try:\n",
    "        # Making a call to create an assistant\n",
    "        assistant = client.beta.assistants.create(\n",
    "            name=\"Party Analyst Assistant\",\n",
    "            instructions=\"You are an expert political analyst. Use your knowledge base to answer questions about party positions.\",\n",
    "            model=\"gpt-4-turbo\",\n",
    "            tools=[{\"type\": \"file_search\"}],\n",
    "        )\n",
    "        print(f\"Assistant created with ID: {assistant.id}\")\n",
    "        return assistant\n",
    "    except Exception as e:\n",
    "        print(\"Failed to create assistant:\", e)\n",
    "        raise HTTPException(status_code=500, detail=f\"Failed to create assistant: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get an assistant, returns the ID of the Political Analyst Assistant if found and creates a new one if not found\n",
    "@backoff.on_exception(backoff.expo, Exception, max_tries=5)\n",
    "async def get_assistant():\n",
    "    try:\n",
    "        # Making a call to list assistantsassistant\n",
    "        response = client.beta.assistants.list()  # Fetching all the assistants\n",
    "        if response and response.data:\n",
    "            for assistant in response.data:\n",
    "                if assistant.name == \"Party Analyst Assistant\":\n",
    "                    print(\"Party Analyst Assistant found.\")\n",
    "                    return assistant\n",
    "            # If no assistant found in the loop, create a new one\n",
    "            print(\"No Party Analyst Assistant found within, creating a new one...\")\n",
    "            assistant = await create_assistant()\n",
    "            return assistant\n",
    "        else:\n",
    "            print(\"No assistants or data available or failed to fetch data, attempting to create a new assistant.\")\n",
    "            assistant = await create_assistant()\n",
    "            return assistant\n",
    "    except Exception as e:\n",
    "        print(\"Failed to fetch assistants:\", e)\n",
    "        raise HTTPException(status_code=500, detail=f\"Failed to fetch assistants: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to ensure the vector store is attached to the assistant\n",
    "@backoff.on_exception(backoff.expo, Exception, max_tries=5)\n",
    "async def ensure_vector_store(assistant):\n",
    "    try:\n",
    "        # Check if the current assistant has the correct vector store attached\n",
    "        vector_store_ids = assistant.tool_resources.file_search.vector_store_ids if assistant.tool_resources and assistant.tool_resources.file_search else []\n",
    "\n",
    "        if vector_store_ids:\n",
    "            # Fetch the vector store details\n",
    "            vector_store = client.beta.vector_stores.retrieve(vector_store_id=vector_store_ids[0])\n",
    "            if vector_store and vector_store.name == \"Party Positions\":\n",
    "                print(\"Correct vector store already attached.\")\n",
    "                return vector_store\n",
    "            else:\n",
    "                print(\"Incorrect vector store attached, looking for correct vector store.\")\n",
    "        else:\n",
    "            print(\"No vector store attached, looking for correct vector store.\")\n",
    "\n",
    "        # If the correct vector store is not attached, check if such a store exists\n",
    "        all_stores = client.beta.vector_stores.list()\n",
    "        party_positions_store = next((store for store in all_stores.data if store.name == \"Party Positions\"), None)\n",
    "\n",
    "        if party_positions_store:\n",
    "            vector_store_id = party_positions_store.id\n",
    "            print(f\"Vector store 'Party Positions' found with ID: {vector_store_id}\")\n",
    "        else:\n",
    "            # Create a new vector store if not found\n",
    "            print(\"Creating new vector store 'Party Positions'\")\n",
    "            vector_store = client.beta.vector_stores.create(name=\"Party Positions\")\n",
    "            vector_store_id = vector_store.id\n",
    "\n",
    "            # Upload files to the new vector store\n",
    "            file_paths = [\"../data/party_positions.pdf\"] # File path to the PDF file\n",
    "            file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "            file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "                vector_store_id=vector_store_id, files=file_streams\n",
    "            )\n",
    "            print(f\"Files uploaded to vector store: {file_batch.status}\")\n",
    "\n",
    "        # Attach the vector store to the assistant\n",
    "        updated_assistant = client.beta.assistants.update(\n",
    "            assistant_id=assistant.id,\n",
    "            tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store_id]}}\n",
    "        )\n",
    "        print(f\"Vector store '{vector_store_id}' attached to assistant.\")\n",
    "        return vector_store\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Failed to ensure vector store:\", e)\n",
    "        raise HTTPException(status_code=500, detail=f\"Failed to ensure vector store: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function to create a new conversation thread\n",
    "@backoff.on_exception(backoff.expo, Exception, max_tries=5)\n",
    "async def create_conversation(assistant, vector_store):\n",
    "    try:\n",
    "        # Create a new conversation thread\n",
    "        thread = client.beta.threads.create(\n",
    "                            messages=conversation_start,\n",
    "                            tool_resources={\n",
    "                                \"file_search\": {\n",
    "                                    \"vector_store_ids\": [vector_store.id]\n",
    "                                }\n",
    "                            }\n",
    "                        )\n",
    "        print(f\"Conversation thread created with ID: {thread.id}\")\n",
    "        \n",
    "        # Create and poll the run\n",
    "        run = client.beta.threads.runs.create_and_poll(\n",
    "            thread_id=thread.id, assistant_id=assistant.id\n",
    "        )\n",
    "        print(f\"Run created with ID: {run.id}\")\n",
    "        return thread, run\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Failed to create conversation: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to run the setup\n",
    "@backoff.on_exception(backoff.expo, Exception, max_tries=5)\n",
    "async def assistant_setup():\n",
    "    try:\n",
    "        # Step 1: Get or create the assistant\n",
    "        assistant = await get_assistant()\n",
    "\n",
    "        # Step 2: Ensure the assistant has the correct vector store attached\n",
    "        vector_store = await ensure_vector_store(assistant)\n",
    "        \n",
    "        # Step 3: Create a new conversation thread\n",
    "        thread, run = await create_conversation(assistant, vector_store)\n",
    "        \n",
    "        # Step 4: Get the response from the assistant\n",
    "        conversation = {}\n",
    "        response = client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id)\n",
    "        conversation['assistant'] = [response.data[0].content[0].text.value]\n",
    "        conversation['user'] = []\n",
    "        return assistant, vector_store, thread, run, conversation\n",
    "\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You're an AI political guide designed to engage in Socratic dialogue. Your goal is to help your discussion \n",
    "partner in self-deliberation about their political opinions. Make sure not to nudge your partner into any \n",
    "political direction but instead be curious and help them find out more deeply what beliefs and opinions they \n",
    "hold and why that is.\n",
    "\n",
    "Begin the conversation with a greeting and and invitation to the discussion partner to share the political \n",
    "topics that concern them the most. Prompt them to select one topic to delve into first.\n",
    "\n",
    "Opening Inquiry: Start with an open-ended question to explore their initial thoughts about the chosen topic:\n",
    "'What concerns you most about this topic and why do you think it's important?'\n",
    "\n",
    "Deepening Understanding: Once they respond, guide them deeper into their reasoning. Ask questions that probe\n",
    "the logic and evidence behind their views: 'What makes you believe that this is the best approach? Can you \n",
    "share examples or evidence that support your opinion?'\n",
    "\n",
    "Introducing Challenges: After understanding their argument, introduce a counterpoint or challenge to their \n",
    "view to test the robustness of their reasoning: 'Have you considered [a specific contradiction or different \n",
    "perspective]? How does this aspect affect your viewpoint?'\n",
    "\n",
    "Reformulating Opinion: Encourage them to reflect on the counterpoint and adjust their opinion if necessary: \n",
    "'Given this new information, how might you refine your perspective on [Topic]?'\n",
    "\n",
    "Continuation or Change: Before moving on, ask if they want to delve deeper into the same topic or switch to \n",
    "another concern: 'Would you like to explore this topic further, or shall we discuss another one of your \n",
    "concerns?'\n",
    "\n",
    "Repeat these steps for each topic they are concerned about. Once all topics are discussed, conclude by \n",
    "asking if there are any additional topics they wish to explore or if they have any final thoughts to share.\n",
    "\n",
    "This approach ensures a thorough, reflective conversation, helping your discussion partner critically \n",
    "examine and potentially broaden and deepen their political perspectives.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "conversation_start = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": system_prompt,\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Party Analyst Assistant found.\n",
      "Correct vector store already attached.\n",
      "Conversation thread created with ID: thread_lNO64NtObYu0vSRsY3ZkwN7H\n",
      "Run created with ID: run_PguHmmBOLDeoZNMtWzV41Sy9\n"
     ]
    }
   ],
   "source": [
    "assistant, vector_store, thread, run, conversation = await assistant_setup() \n",
    "conversation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Chatbot Completion Function for assistants API\n",
    "@backoff.on_exception(backoff.expo, Exception, max_tries=5)\n",
    "async def chatbot_completion(\n",
    "    message,\n",
    "    assistant,\n",
    "    thread,\n",
    "    run,\n",
    "    conversation\n",
    "    ):\n",
    "    try:\n",
    "        conversation[\"user\"].append(message)\n",
    "        # Create a message to append to our thread\n",
    "        message = client.beta.threads.messages.create(\n",
    "            thread_id=thread.id, role='user', content=message)\n",
    "        \n",
    "        # Execute our run\n",
    "        run = client.beta.threads.runs.create_and_poll(\n",
    "            thread_id=thread.id,\n",
    "            assistant_id=assistant.id,\n",
    "        )\n",
    "        response = client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id)\n",
    "        conversation['assistant'].append(response.data[0].content[0].text.value)\n",
    "\n",
    "        return conversation\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'assistant': [\"Hello! I'm here to help you explore and reflect on your political opinions through a Socratic dialogue. To begin, could you share some political topics that currently concern you the most? Please feel free to list a few, and then we can select one to delve into deeply first.\",\n",
       "  \"Thank you for sharing your concern about job security and the impact of immigration on employment. Let's delve into this topic a bit deeper.\\n\\nWhat concerns you most about this topic and why do you think it's important?\",\n",
       "  \"It sounds like you're deeply concerned about the welfare and financial stability of long-standing communities and their ability to find sustainable employment. \\n\\nWhat makes you believe that the presence of immigrants is a primary factor affecting job availability for locals? Can you share any specific examples or evidence that support your opinion?\"],\n",
       " 'user': [\"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  \"It's the job security, the immigrants are taking our jobs!\",\n",
       "  'I believe a lot of people that belong here and are working hard are not getting the jobs they need to sustain their families.']}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = await chatbot_completion(\n",
    "    message=\"I believe a lot of people that belong here and are working hard are not getting the jobs they need to sustain their families.\",\n",
    "    assistant=assistant,\n",
    "    thread=thread,\n",
    "    run=run,\n",
    "    conversation=conversation\n",
    "    )\n",
    "conversation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delibenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
