{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import backoff\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from fastapi import HTTPException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.beta.assistants.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39massistants\u001b[38;5;241m.\u001b[39mdelete(\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mid)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "client.beta.assistants.delete(response.data[0].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.beta.vector_stores.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mvector_stores\u001b[38;5;241m.\u001b[39mdelete(\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mid)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "client.beta.vector_stores.delete(response.data[0].id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As in openai_assistant.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create an assistant, if not found\n",
    "@backoff.on_exception(backoff.expo, Exception, max_tries=5)\n",
    "async def create_assistant():\n",
    "    try:\n",
    "        # Making a call to create an assistant\n",
    "        assistant = client.beta.assistants.create(\n",
    "            name=\"Party Analyst Assistant\",\n",
    "            instructions=\"You are an expert political analyst. Use your knowledge base to answer questions about party positions.\",\n",
    "            model=\"gpt-4-turbo\",\n",
    "            tools=[{\"type\": \"file_search\"}],\n",
    "        )\n",
    "        print(f\"Assistant created with ID: {assistant.id}\")\n",
    "        return assistant\n",
    "    except Exception as e:\n",
    "        print(\"Failed to create assistant:\", e)\n",
    "        raise HTTPException(status_code=500, detail=f\"Failed to create assistant: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get an assistant, returns the ID of the Political Analyst Assistant if found and creates a new one if not found\n",
    "@backoff.on_exception(backoff.expo, Exception, max_tries=5)\n",
    "async def get_assistant():\n",
    "    try:\n",
    "        # Making a call to list assistantsassistant\n",
    "        response = client.beta.assistants.list()  # Fetching all the assistants\n",
    "        if response and response.data:\n",
    "            for assistant in response.data:\n",
    "                if assistant.name == \"Party Analyst Assistant\":\n",
    "                    print(\"Party Analyst Assistant found.\")\n",
    "                    return assistant\n",
    "            # If no assistant found in the loop, create a new one\n",
    "            print(\"No Party Analyst Assistant found within, creating a new one...\")\n",
    "            return create_assistant()\n",
    "        else:\n",
    "            print(\"No assistants or data available or failed to fetch data, attempting to create a new assistant.\")\n",
    "            return create_assistant()\n",
    "    except Exception as e:\n",
    "        print(\"Failed to fetch assistants:\", e)\n",
    "        raise HTTPException(status_code=500, detail=f\"Failed to fetch assistants: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to ensure the vector store is attached to the assistant\n",
    "@backoff.on_exception(backoff.expo, Exception, max_tries=5)\n",
    "async def ensure_vector_store(assistant):\n",
    "    try:\n",
    "        # Check if the current assistant has the correct vector store attached\n",
    "        vector_store_ids = assistant.tool_resources.file_search.vector_store_ids if assistant.tool_resources and assistant.tool_resources.file_search else []\n",
    "\n",
    "        if vector_store_ids:\n",
    "            # Fetch the vector store details\n",
    "            vector_store = client.beta.vector_stores.retrieve(vector_store_id=vector_store_ids[0])\n",
    "            if vector_store and vector_store.name == \"Party Positions\":\n",
    "                print(\"Correct vector store already attached.\")\n",
    "                return vector_store_ids[0]\n",
    "            else:\n",
    "                print(\"Incorrect vector store attached, looking for correct vector store.\")\n",
    "        else:\n",
    "            print(\"No vector store attached, looking for correct vector store.\")\n",
    "\n",
    "        # If the correct vector store is not attached, check if such a store exists\n",
    "        all_stores = client.beta.vector_stores.list()\n",
    "        party_positions_store = next((store for store in all_stores.data if store.name == \"Party Positions\"), None)\n",
    "\n",
    "        if party_positions_store:\n",
    "            vector_store_id = party_positions_store.id\n",
    "            print(f\"Vector store 'Party Positions' found with ID: {vector_store_id}\")\n",
    "        else:\n",
    "            # Create a new vector store if not found\n",
    "            print(\"Creating new vector store 'Party Positions'\")\n",
    "            vector_store = client.beta.vector_stores.create(name=\"Party Positions\")\n",
    "            vector_store_id = vector_store.id\n",
    "\n",
    "            # Upload files to the new vector store\n",
    "            file_paths = [\"data/party_positions.pdf\"] # File path to the PDF file\n",
    "            file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "            file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "                vector_store_id=vector_store_id, files=file_streams\n",
    "            )\n",
    "            print(f\"Files uploaded to vector store: {file_batch.status}\")\n",
    "\n",
    "        # Attach the vector store to the assistant\n",
    "        updated_assistant = client.beta.assistants.update(\n",
    "            assistant_id=assistant.id,\n",
    "            tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store_id]}}\n",
    "        )\n",
    "        print(f\"Vector store '{vector_store_id}' attached to assistant.\")\n",
    "        return vector_store_id\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Failed to ensure vector store:\", e)\n",
    "        raise HTTPException(status_code=500, detail=f\"Failed to ensure vector store: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to run the setup\n",
    "@backoff.on_exception(backoff.expo, Exception, max_tries=5)\n",
    "async def assistant_setup():\n",
    "    try:\n",
    "        # Step 1: Get or create the assistant\n",
    "        assistant = await get_assistant()\n",
    "        print(f\"Assistant retrieved or created with ID: {assistant.id}\")\n",
    "\n",
    "        # Step 2: Ensure the assistant has the correct vector store attached\n",
    "        vector_store_id = await ensure_vector_store(assistant)\n",
    "        print(f\"Assistant is now correctly configured with vector store ID: {vector_store_id}\")\n",
    "        \n",
    "        return assistant\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred in the main setup:\", e)\n",
    "        raise HTTPException(status_code=500, detail=str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not implemented yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the user provided file to OpenAI\n",
    "message_file = client.files.create(\n",
    "  file=open(\"party_positions.pdf\", \"rb\"), purpose=\"assistants\"\n",
    ")\n",
    " \n",
    "# Create a thread and attach the file to the message\n",
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"I care deeply about the environment and therefore I believe we can't handle more immigration in germany. What party matches my beliefs?\",\n",
    "      # Attach the new file to the message.\n",
    "      \"attachments\": [\n",
    "        { \"file_id\": message_file.id, \"tools\": [{\"type\": \"file_search\"}] }\n",
    "      ],\n",
    "    }\n",
    "  ]\n",
    ")\n",
    " \n",
    "# The thread now has a vector store with that file in its tool resources.\n",
    "print(thread.tool_resources.file_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the create and poll SDK helper to create a run and poll the status of \n",
    "# the run until it's in a terminal state.\n",
    "\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id, assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
    "\n",
    "message_content = messages[0].content[0].text\n",
    "annotations = message_content.annotations\n",
    "citations = []\n",
    "for index, annotation in enumerate(annotations):\n",
    "    message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
    "    if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "        cited_file = client.files.retrieve(file_citation.file_id)\n",
    "        citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "print(message_content.value)\n",
    "print(\"\\n\".join(citations))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delibenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
